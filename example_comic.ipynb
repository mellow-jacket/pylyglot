{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for producing a full issue\n",
    "\n",
    "Please see readme for notes on using ctpy\n",
    "\n",
    "The test case is comitted to the git repo. \n",
    "You will need to delete raw_chapters/test/ to rebuild from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pylyglot as glot\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Use the API key from .env OR set it as None\n",
    "api_key = os.getenv('API_KEY')\n",
    "gemini_key = os.getenv('VERTEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name will determine the name used in raw_chapeters and final_chapters\n",
    "# url is used only for scrape()\n",
    "test = glot.issue(\n",
    "    name='example_comic',\n",
    "    url = 'test_data\\comic', # None uses test_images\n",
    "    api_key = api_key,\n",
    "    gemini_key=gemini_key\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to clean out the working directory before rescraping\n",
    "test.clear_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes .jpegs from the specified url\n",
    "\n",
    "# tested working with newtoki and mangademon\n",
    "test.scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the iamges may be split at strange places. \n",
    "# I use these methods to split and combine the pages before downsampling\n",
    "\n",
    "#glot.split_file('raw_chapters/examples/raw_images/page_num_0.jpeg')\n",
    "#glot.separate_file('raw_chapters/examples/raw_images/page_num_0.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.downsample(scale_factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages can be combined, but we will leave them separate in the test\n",
    "\n",
    "#test.combine_pages(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autobox text and perform OCR on the images\n",
    "test.autobox()\n",
    "test.perform_ocr_on_all_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be buggy/laggy\n",
    "# use start = , stop =  to only load a smaller number of images\n",
    "\n",
    "\n",
    "#drawer = glot.BoxDrawer(test)\n",
    "#drawer.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check raw_chapters/test/gpt_images/\n",
    "# this aspect of the code is in-flux\n",
    "# the best way to feed images to the models is not determined\n",
    "# 12/22/2023 - plan is to try to remove images and just use OCR + llm-no-vision to minimize cost\n",
    "# novel supports OCR w/ no vision, comic is not there yet.\n",
    "\n",
    "model = 'gemini' # or 'gpt'\n",
    "\n",
    "# pipe those images to the AI\n",
    "# prompt will be saved in raw_chapters/test/prompts\n",
    "# response saved in raw_chapters/test/response -and- /text\n",
    "if model == 'gemini':\n",
    "    test.add_boxes_to_images()\n",
    "    test.copy_to_gpt_images()\n",
    "else:\n",
    "    test.add_boxes_to_images()\n",
    "    test.combine_gpt_and_ocr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'gemini':\n",
    "    test.translate(model='gemini')\n",
    "else:\n",
    "    test.translate(model='gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf is formatted automatically\n",
    "# It can be weird if your images are too big or small\n",
    "test.make_pdf()\n",
    "\n",
    "# this test may report 'failed response'\n",
    "# check the response, sometimes GPT just says no.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comic_translator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
