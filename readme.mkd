# Pylyglot
## Translate webtoons and webnovels with python

The goal of this project is to provide something to fill the gap between a raw release and an official/unofficial translation.

Recent attention has been focused on translating the Skeleton Soldier web novel.

In theory this tool could be applied to many sotries and languages, but I have no immediate plans outside of Korean -> English  for Skeleton Soldier.

[View an example translation](/final_chapters/example.pdf)

[Google drive link to translated chapters](https://drive.google.com/drive/folders/1svq-2SuqnTngff66doalNcpf7AWxJE8g?usp=drive_link)


## Setup and installation

This module will require conda for setting up the enviroment. 
Other methods can be used, but are not described in this readme.

To follow this guide download miniconda from [here](https://docs.conda.io/projects/miniconda/en/latest/)

This [youtube video](https://www.youtube.com/watch?v=XCvgyvBFjyM) can help you get things running if you do not do any python

You will need to create a file named ".env"

In this file, paste your api_key as...

   API_KEY='your_openai_key'
   VERTEX='your_vertex_key'

With conda on your system path run...

    conda create --name py_translator python=3.11.6

    conda activate py_translator

    pip install -r requirements.txt

Test installation

    pytest

Pytest should run succesffully if everything is set up

Check out example_comic.ipynb to see an example webtoon.

Check out example_novel.ipynb so see an example webnovel.

Code to produce translated issues is in /notebooks. 

The raw_chapters and final_chapters for these are not committed.

# Initialize issue class

 - name determines the name in raw_ and final_chapters
 - url only used in scrape. Specify file or folder or use local images.
 - api_key = None will run in a debug mode

        import pylyglot as glot
        issue = glot.issue(name='example',url = <local_path or url>, api_key = api_key )

# Scraping images

      issue.scrape() 

 - NOT safe to call twice
 - it should be called once then commented out
  
# Image formatting tools

 Scraped images are not conveniently formatted, use these tools to fix them
 Do not call on first or last image (page_num_1 or page_num_#final)

 split file at click, combine top with previous, bottom with next, reindex names

      glot.split_file(rel_path)

 split file at click, two new files, reindex names

      glot.separate_file(rel_path) 

 older combine based on raw_image numbering [must run after downsample]

      issue.combine_pages(page1, page2)


# Change resolution & prepare OCR

      issue.downsample(scale_factor = float)

   - resample image, prepare for OCR, save raw for pdf
   - must be called

# BoxDrawer

note: progress has been made on autoboxing of text. More refinements are needed to integrate easyOCR.

A user must go through each image and draw a box around text.
You can press 'previous', 'next', or 'quit' to move images.
Press next when you are done drawing boxes on an image.
Press next without drawing boxes if there is no text.
Focus on text in text boxes, not sound effects.

This process isn't strictly necessary. It does improve the performance of both OCR and GPT. 

      drawer = glot.BoxDrawer(test,start = 0, end = 20)

      drawer.draw()

 - start/end specified so that the notebook doesnt crash [maybe not needed?]
 - click corners to define a box around all text
 - Use zoom and pan features as needed
 - Click start drawing button to turn on/off box drawing
 - Use load or clear to load any saved boxes, or clear them from the images.
 - You can use issue.autobox() to get initial boxes, and load and clear+redraw as needed

Save any drawn boxes outside of the raw_chapters folder with this

      drawer.save(name = 'any_name')

Load any previous saved boxes with this

      drawer.load(name = name)

The novel does not currently require any boxing of text due to sufficient image splitting.

# Combine OCR image for GPT

      issue.combine_gpt_and_ocr()

   - Horizontally concat OCR image to normal image.
   - Improves GPT performance, but its more expensive for a bigger image
   - This call is not needed, but the prompt may need to be changed.

This part of the code is in-flux. I aim to remove the need for vision models due to their expense.

Other options for the vision model image generation are

      issue.tile_images_for_gpt() attempts at zooming in on images boxes. Mid success
      issue.copy_images_to_gpt() Just use the base image with no adjustments. Good with gemini
      issue.add_boxes_to_images() Method that will redbox any boxes in the /images folder
                                  It can be used to add red boxes before calling other methods

# Translate page and make the pdf

   - Automatically calls gpt on image with a specified prompt
   - The prompt is defined in ctpy/translate.py 

         issue.translate(model='gpt)

   - For the novel call...

         issue.translate_text(model='gpt')

   - To use gemini instead of gpt specify model = 'gemini
   - Bind everything into a pdf

         issue.make_pdf()

